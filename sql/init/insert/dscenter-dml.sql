-- 数据源中心支持的产品列表
INSERT INTO `dsc_app_list` (`id`, `app_type`, `app_code`, `app_name`, `invisible`, `is_deleted`, `gmt_create`, `gmt_modified`, `create_user_id`, `modify_user_id`, `sorted`)
VALUES
	(1, 1, 'batch', '离线开发', 0, 0, '2021-03-15 17:46:26', '2021-03-26 11:04:30', 0, 0, 10),
	(2, 2, 'valid', '数据质量', 0, 0, '2021-03-15 17:46:26', '2021-03-26 11:05:14', 0, 0, 5),
	(3, 3, 'api', '数据服务', 0, 0, '2021-03-15 17:46:26', '2021-03-26 11:04:55', 0, 0, 7),
	(4, 4, 'tag', '智能标签', 1, 0, '2021-03-15 17:46:26', '2021-03-26 11:05:52', 0, 0, 0),
	(5, 5, 'map', '数据地图', 1, 0, '2021-03-15 17:46:26', '2021-03-26 11:05:52', 0, 0, 0),
	(6, 6, 'console', '控制台', 1, 0, '2021-03-15 17:46:26', '2021-03-26 11:05:53', 0, 0, 0),
	(7, 7, 'stream', '实时开发', 0, 0, '2021-03-15 17:46:26', '2021-03-26 11:04:39', 0, 0, 9),
	(8, 8, 'ai', '算法开发', 0, 0, '2021-03-15 17:46:26', '2021-03-26 11:04:45', 0, 0, 8),
	(9, 9, 'assets', '数据资产', 0, 0, '2021-03-15 17:46:26', '2021-03-26 11:05:11', 0, 0, 6),
	(10, 10, 'index', '指标平台', 1, 0, '2021-03-15 17:46:26', '2021-03-26 11:05:11', 0, 0, 0);

-- 数据源和产品映射表
INSERT INTO `dsc_app_mapping` (`id`, `app_type`, `data_type`, `data_version`, `is_deleted`, `gmt_create`, `gmt_modified`, `create_user_id`, `modify_user_id`)
VALUES
	(1, 1, 'MySQL', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(2, 1, 'PolarDB for MySQL8', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(3, 1, 'Oracle', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(4, 1, 'SQLServer', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(5, 1, 'PostgreSQL', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(6, 1, 'DB2', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(7, 1, 'DMDB', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(8, 1, 'KingbaseES8', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(9, 1, 'Hive', '1.x', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(10, 1, 'Hive', '2.x', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(11, 1, 'Maxcompute', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(12, 1, 'Greenplum', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(13, 1, 'GaussDB', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(14, 1, 'GBase_8a', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(15, 1, 'HDFS', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(16, 1, 'FTP', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(17, 1, 'Impala', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(18, 1, 'ClickHouse', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(19, 1, 'TiDB', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(20, 1, 'CarbonData', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(21, 1, 'Kudu', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(22, 1, 'Kylin', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(23, 1, 'HBase', '1.x', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(24, 1, 'Phoenix', '4.x', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(25, 1, 'Phoenix', '5.x', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(26, 1, 'Elasticsearch', '5.x', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(27, 1, 'MongoDB', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(28, 1, 'Redis', '', 0, '2021-03-24 14:42:21', '2021-03-24 14:42:31', 0, 0),
	(29, 7, 'MySQL', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:31', 0, 0),
	(30, 7, 'PolarDB for MySQL8', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:31', 0, 0),
	(31, 7, 'Oracle', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:31', 0, 0),
	(32, 7, 'SQLServer', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(33, 7, 'PostgreSQL', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(34, 7, 'DB2', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(35, 7, 'KingbaseES8', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(36, 7, 'Hive', '2.x', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(37, 7, 'S3', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(38, 7, 'HDFS', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(39, 7, 'Impala', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(40, 7, 'ClickHouse', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(41, 7, 'TiDB', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(42, 7, 'Kudu', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(43, 7, 'HBase', '1.x', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(44, 7, 'Elasticsearch', '5.x', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(45, 7, 'Elasticsearch', '6.x', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(46, 7, 'Elasticsearch', '7.x', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(47, 7, 'MongoDB', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(48, 7, 'Redis', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(49, 7, 'Kafka', '2.x', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(50, 7, 'Kafka', '1.x', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(51, 7, 'Kafka', '0.9', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(52, 7, 'Kafka', '0.10', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(53, 7, 'Kafka', '0.11', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(54, 7, 'EMQ', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(55, 7, 'WebSocket', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(56, 7, 'Socket', '', 0, '2021-03-24 14:42:22', '2021-03-24 14:42:32', 0, 0),
	(57, 8, 'Hive', '1.x', 0, '2021-03-24 14:42:23', '2021-03-24 14:42:33', 0, 0),
	(58, 8, 'Hive', '2.x', 0, '2021-03-24 14:42:23', '2021-03-24 14:42:33', 0, 0),
	(59, 3, 'MySQL', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(60, 3, 'Oracle', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(61, 3, 'SQLServer', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(62, 3, 'PostgreSQL', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(63, 3, 'DB2', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(64, 3, 'KingbaseES8', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(65, 3, 'Impala', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(66, 3, 'TiDB', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(67, 3, 'Kylin', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(68, 3, 'HBase', '1.x', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(69, 3, 'HBase', '2.x', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(70, 3, 'Elasticsearch', '6.x', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(71, 3, 'Elasticsearch', '7.x', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(72, 3, 'MongoDB', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(73, 9, 'MySQL', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(74, 9, 'Oracle', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(75, 9, 'SQLServer', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(76, 9, 'TiDB', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(77, 9, 'Hive', '1.x', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(78, 9, 'Hive', '2.x', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:33', 0, 0),
	(79, 2, 'MySQL', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:34', 0, 0),
	(80, 2, 'Oracle', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:34', 0, 0),
	(81, 2, 'SQLServer', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:34', 0, 0),
	(82, 2, 'Hive', '2.x', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:34', 0, 0),
	(83, 2, 'Maxcompute', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:34', 0, 0),
	(84, 2, 'TiDB', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:34', 0, 0),
	(85, 2, 'Greenplum', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:34', 0, 0),
	(86, 2, 'KingbaseES8', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:34', 0, 0),
	(87, 2, 'SparkThrift', '', 0, '2021-03-24 14:42:24', '2021-03-24 14:42:34', 0, 0),
	(88, 4, 'Presto', '', 0, '2021-03-24 14:42:25', '2021-03-24 14:42:34', 0, 0),
	(89, 7, 'Solr', '7.x', 0, '2021-05-28 13:49:00', '2021-05-28 13:49:00', 0, 0),
	(90, 9, 'Phoenix', '5.x', 0, '2021-06-03 14:56:21', '2021-06-03 14:56:21', 0, 0),
	(91, 9, 'HBase', '1.x', 0, '2021-06-03 14:56:21', '2021-06-03 14:56:21', 0, 0),
	(92, 9, 'Kafka', '0.10', 0, '2021-06-03 14:56:21', '2021-06-03 14:56:21', 0, 0),
	(93, 9, 'Kafka', '2.x', 0, '2021-06-03 14:56:21', '2021-06-03 14:56:21', 0, 0),
	(94, 1,'InfluxDB', '1.x', 0, '2021-06-09 14:49:27', '2021-06-09 14:49:42', 0, 0),
	(95, 9, 'SparkThrift', '', 0, '2021-06-15 10:51:24', '2021-06-15 10:51:24', 0, 0),
	(96, 1, 'AWS S3', '', 0, '2021-06-21 19:48:27', '2021-06-21 19:48:27', 0, 0),
	(97, 1, 'Inceptor', '', 0, '2021-06-21 22:07:27', '2021-06-21 22:07:27', 0, 0),
	(98, 1, 'SparkThrift', '', 0, '2021-06-28 10:08:27', '2021-06-28 10:08:27', 0, 0),
	(99, 3, 'AnalyticDB', '', 0, '2021-06-28 21:06:21', '2021-06-28 21:06:21', 0, 0),
	(100, 1, 'ADB_PostgreSQL','', 0, '2021-06-01 12:22:10', '2021-06-01 12:22:10', 0, 0),
    (101, 7, 'ADB_PostgreSQL','', 0, '2021-06-01 12:22:10', '2021-06-01 12:22:10', 0, 0),
    (102, 9, 'Vertica','', 0,'2021-06-01 12:22:10', '2021-06-01 12:22:10', 0, 0),
	(103, 2, 'Kafka', '2.x', 0, '2021-06-30 14:55:21', '2021-06-30 14:55:21', 0, 0),
    (104, 2, 'Kafka', '0.10', 0, '2021-06-30 14:55:21', '2021-06-30 14:55:21', 0, 0)
	;

-- 数据源分类表
INSERT INTO `dsc_classify` (`id`, `classify_code`, `sorted`, `classify_name`, `is_deleted`, `gmt_create`, `gmt_modified`, `create_user_id`, `modify_user_id`)
VALUES
	(1, 'total', 100, '全部', 0, '2021-03-15 17:49:27', '2021-03-15 17:50:42', 0, 0),
	(2, 'mostUse', 90, '常用', 0, '2021-03-15 17:49:27', '2021-03-15 17:50:43', 0, 0),
	(3, 'relational', 80, '关系型', 0, '2021-03-15 17:49:27', '2021-03-15 17:50:43', 0, 0),
	(4, 'bigData', 70, '大数据存储', 0, '2021-03-15 17:49:27', '2021-03-15 17:50:43', 0, 0),
	(5, 'mpp', 60, 'MPP', 0, '2021-03-15 17:49:27', '2021-03-15 17:50:43', 0, 0),
	(6, 'semiStruct', 50, '半结构化', 0, '2021-03-15 17:49:27', '2021-03-15 17:50:43', 0, 0),
	(7, 'analytic', 40, '分析型', 0, '2021-03-15 17:49:27', '2021-03-15 17:50:44', 0, 0),
	(8, 'NoSQL', 30, 'NoSQL', 0, '2021-03-15 17:49:27', '2021-03-15 17:50:44', 0, 0),
	(9, 'actualTime', 20, '实时', 0, '2021-03-15 17:49:27', '2021-03-15 17:50:44', 0, 0),
	(10, 'api', 0, '接口', 0, '2021-03-15 17:49:27', '2021-03-15 17:50:44', 0, 0),
	(11, 'sequential', 10, '时序', 0, '2021-06-09 17:19:27', '2021-06-09 17:19:27', 0, 0)
	;

-- 数据源类型信息表
INSERT INTO `dsc_type` (`id`, `data_type`, `data_classify_id`, `weight`, `img_url`, `is_deleted`, `gmt_create`, `gmt_modified`, `create_user_id`, `modify_user_id`, `sorted`, `invisible`)
VALUES
	(1, 'MySQL', 3, 0.5, 'MySQL.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 2500, 0),
	(2, 'PolarDB for MySQL8', 3, 0.0, 'PolarDB for MySQL8.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 2450, 0),
	(3, 'Oracle', 3, 0.5, 'Oracle.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 2400, 0),
	(4, 'SQLServer', 3, 0.0, 'SQLServer.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 2350, 0),
	(5, 'PostgreSQL', 3, 0.0, 'PostgreSQL.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 2300, 0),
	(6, 'DB2', 3, 0.0, 'DB2.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 2250, 0),
	(7, 'DMDB', 3, 0.0, 'DMDB.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 2200, 0),
	(8, 'KingbaseES8', 3, 0.0, 'KingbaseES8.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 2100, 0),
	(9, 'Hive', 4, 0.5, 'Hive.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 2050, 0),
	(10, 'SparkThrift', 4, 0.0, 'SparkThrift.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 2000, 0),
	(11, 'Maxcompute', 4, 0.0, 'Maxcompute.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1950, 0),
	(12, 'Phoenix', 4, 0.0, 'Phoenix.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1900, 0),
	(13, 'Greenplum', 5, 0.0, 'Greenplum.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1850, 0),
	(14, 'GaussDB', 5, 0.0, 'GaussDB.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1800, 0),
	(15, 'GBase_8a', 5, 0.0, 'GBase_8a.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1750, 0),
	(16, 'HDFS', 6, 0.0, 'HDFS.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1700, 0),
	(17, 'FTP', 6, 0.0, 'FTP.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1650, 0),
	(18, 'S3', 6, 0.0, 'S3.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1600, 0),
	(19, 'Impala', 7, 0.0, 'Impala.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1550, 0),
	(20, 'ClickHouse', 7, 0.0, 'ClickHouse.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1500, 0),
	(21, 'TiDB', 7, 0.0, 'TiDB.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1450, 0),
	(22, 'Kudu', 7, 0.0, 'Kudu.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1400, 0),
	(23, 'AnalyticDB', 7, 0.0, 'AnalyticDB.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1350, 0),
	(24, 'CarbonData', 7, 0.0, 'CarbonData.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1300, 0),
	(25, 'Kylin', 7, 0.0, 'Kylin.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1250, 0),
	(26, 'HBase', 8, 0.0, 'HBase.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1200, 0),
	(27, 'Elasticsearch', 8, 0.0, 'Elasticsearch.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1150, 0),
	(28, 'MongoDB', 8, 0.0, 'MongoDB.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1050, 0),
	(29, 'Redis', 8, 0.0, 'Redis.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 1000, 0),
	(30, 'Kafka', 9, 0.5, 'Kafka.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 950, 0),
	(31, 'EMQ', 9, 0.0, 'EMQ.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 900, 0),
	(32, 'WebSocket', 10, 0.0, 'WebSocket.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 850, 0),
	(33, 'Socket', 10, 0.0, 'Socket.png', 0, '2021-03-15 17:50:44', '2021-05-28 11:18:00', 0, 0, 800, 0),
	(34, 'Presto', 1, 0.0, NULL, 0, '2021-03-24 12:01:00', '2021-05-28 11:18:00', 0, 0, 750, 1),
	(35,'Solr',8,0.0,'Solr.png',0,'2021-05-28 11:18:00','2021-05-28 11:18:00',0,0,1100,0),
	(36,'InfluxDB', 11, 10.0, 'InfluxDB.png', 0, '2021-06-09 14:49:27', '2021-06-09 14:49:42', 0, 0, 875, 0),
	(37,'AWS S3', 6, 0.0, 'AWS S3.png', 0, '2021-06-21 19:48:27', '2021-06-21 19:48:27', 0, 0, 1575, 0),
	(38,'Inceptor', 4, 0.0, 'Inceptor.png', 0, '2021-06-21 22:07:27', '2021-06-21 22:07:27', 0, 0, 1875, 0),
	(39,'ADB_PostgreSQL',7,0.0,'ADB_PostgreSQL.png',0,'2021-06-01 12:22:10','2021-06-01 12:22:10',0,0,1220,0),
	(40,'Vertica',5,0.0,'Vertica.png',0,'2021-06-01 12:22:10','2021-06-01 12:22:10',0,0,1720,0)
	;


-- 数据源版本表
INSERT INTO `dsc_version` (`id`, `data_type`, `data_version`, `sorted`, `is_deleted`, `gmt_create`, `gmt_modified`, `create_user_id`, `modify_user_id`)
VALUES
	(1, 'Hive', '1.x', 0, 0, '2021-03-15 17:51:55', '2021-03-15 17:53:11', 0, 0),
	(2, 'Hive', '2.x', 1, 0, '2021-03-15 17:51:55', '2021-03-15 17:54:16', 0, 0),
	(3, 'HBase', '1.x', 0, 0, '2021-03-15 17:51:55', '2021-03-15 17:53:11', 0, 0),
	(4, 'HBase', '2.x', 1, 0, '2021-03-15 17:51:55', '2021-03-15 17:54:38', 0, 0),
	(5, 'Phoenix', '4.x', 0, 0, '2021-03-15 17:51:55', '2021-03-15 17:53:11', 0, 0),
	(6, 'Phoenix', '5.x', 1, 0, '2021-03-15 17:51:55', '2021-04-01 14:43:21', 0, 0),
	(7, 'Elasticsearch', '5.x', 0, 0, '2021-03-15 17:51:55', '2021-03-15 17:53:11', 0, 0),
	(8, 'Elasticsearch', '6.x', 1, 0, '2021-03-15 17:51:55', '2021-03-15 17:54:24', 0, 0),
	(9, 'Elasticsearch', '7.x', 2, 0, '2021-03-15 17:51:55', '2021-03-15 17:54:24', 0, 0),
	(10, 'Kafka', '1.x', 3, 0, '2021-03-15 17:51:55', '2021-03-15 17:54:54', 0, 0),
	(11, 'Kafka', '2.x', 4, 0, '2021-03-15 17:51:55', '2021-03-15 17:54:49', 0, 0),
	(12, 'Kafka', '0.9', 0, 1, '2021-03-15 17:51:55', '2021-03-15 17:53:11', 0, 0),
	(13, 'Kafka', '0.10', 1, 0, '2021-03-15 17:51:55', '2021-03-15 17:54:56', 0, 0),
	(14, 'Kafka', '0.11', 2, 0, '2021-03-15 17:51:55', '2021-03-15 17:54:55', 0, 0),
	(15, 'Solr', '7.x', 0, 0, '2021-05-28 14:48:00', '2021-05-28 14:48:00', 0, 0),
	(16,'InfluxDB', '1.x', 0, 0, '2021-06-09 14:49:27', '2021-06-09 14:49:42', 0, 0)
	;

-- 数据源模版表单属性表
INSERT INTO `dsc_form_field` (`id`, `name`, `label`, `widget`, `required`, `invisible`, `default_value`, `place_hold`, `request_api`, `is_link`, `valid_info`, `tooltip`, `style`, `regex`, `type_version`, `is_deleted`, `gmt_create`, `gmt_modified`, `create_user_id`, `modify_user_id`,`options`)
VALUES
    (1, 'dataName', '数据源名称', 'Input', 1, 0, NULL, NULL, NULL, 0, '{\"length\":{\"max\":128, \"message\":\"不得超过128个字符\"}}', NULL, NULL, NULL, 'common', 0, '2021-03-15 17:33:21', '2021-03-30 16:09:06', 0, 0,''),
    (2, 'dataDesc', '描述', 'TextArea', 0, 0, NULL, NULL, NULL, 0, '{\"length\":{\"max\":200, \"message\":\"不得超过200个字符\"}}', NULL, NULL, NULL, 'common', 0, '2021-03-15 17:33:21', '2021-03-30 16:09:15', 0, 0,''),
    (3, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:mysql://host:port/dbName', NULL, '/jdbc:mysql:\\/\\/(.)+/', 'MySQL', 0, '2021-03-23 20:35:57', '2021-03-30 16:07:17', 0, 0,''),
    (4, 'username', '用户名', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'MySQL', 0, '2021-03-23 20:35:57', '2021-03-30 16:08:46', 0, 0,''),
    (5, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'MySQL', 0, '2021-03-23 20:35:57', '2021-03-30 16:08:46', 0, 0,''),
    (6, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:mysql://host:port/dbName', NULL, '/jdbc:mysql:\\/\\/(.)+/', 'PolarDB for MySQL8', 0, '2021-03-23 20:35:57', '2021-03-30 16:07:17', 0, 0,''),
    (7, 'username', '用户名', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'PolarDB for MySQL8', 0, '2021-03-23 20:35:57', '2021-03-30 16:08:46', 0, 0,''),
    (8, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'PolarDB for MySQL8', 0, '2021-03-23 20:35:57', '2021-03-30 16:08:46', 0, 0,''),
    (9, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', 'SID示例：jdbc:oracle:thin:@host:port:dbName\nServiceName示例：jdbc:oracle:thin:@//host:port/service_name', NULL, '/jdbc:oracle:thin:@(\\/\\/)?(.)+/', 'Oracle', 0, '2021-03-23 20:35:57', '2021-03-30 16:07:17', 0, 0,''),
    (10, 'username', '用户名', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'Oracle', 0, '2021-03-23 20:35:57', '2021-03-30 16:08:46', 0, 0,''),
    (11, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Oracle', 0, '2021-03-23 20:35:57', '2021-03-30 16:08:46', 0, 0,''),
    (12, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '', '示例：jdbc:sqlserver://localhost:1433;DatabaseName=dbName\n或\n jdbc:jtds:sqlserver://localhost:1433/dbName', NULL, '', 'SQLServer', 0, '2021-03-23 20:35:57', '2021-03-30 16:07:17', 0, 0,''),
    (13, 'username', '用户名', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'SQLServer', 0, '2021-03-23 20:35:57', '2021-04-02 16:50:08', 0, 0,''),
    (14, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'SQLServer', 0, '2021-03-23 20:35:57', '2021-04-02 16:50:10', 0, 0,''),
    (15, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:postgresql://host:port/database', NULL, '/jdbc:postgresql:\\/\\/(.)+/', 'PostgreSQL', 0, '2021-03-23 20:35:57', '2021-03-30 16:07:17', 0, 0,''),
    (16, 'username', '用户名', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'PostgreSQL', 0, '2021-03-23 20:35:57', '2021-04-02 16:50:17', 0, 0,''),
    (17, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'PostgreSQL', 0, '2021-03-23 20:35:57', '2021-04-02 16:50:18', 0, 0,''),
    (18, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:db2://host:port/dbName', NULL, '/jdbc:db2:\\/\\/(.)+/', 'DB2', 0, '2021-03-23 20:35:58', '2021-03-30 16:07:17', 0, 0,''),
    (19, 'username', '用户名', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'DB2', 0, '2021-03-23 20:35:58', '2021-04-13 16:31:26', 0, 0,''),
    (20, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'DB2', 0, '2021-03-23 20:35:58', '2021-04-13 16:31:27', 0, 0,''),
    (21, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:dm://host:port/database', NULL, '/jdbc:dm:\\/\\/(.)+/', 'DMDB', 0, '2021-03-23 20:35:58', '2021-03-30 16:07:17', 0, 0,''),
    (22, 'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'DMDB', 0, '2021-03-23 20:35:58', '2021-03-30 16:08:46', 0, 0,''),
    (23, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'DMDB', 0, '2021-03-23 20:35:58', '2021-03-30 16:08:46', 0, 0,''),
    (24, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:kingbase8://host:port/database', NULL, '/jdbc:kingbase8:\\/\\/(.)+/', 'KingbaseES8', 0, '2021-03-23 20:35:58', '2021-03-30 16:07:17', 0, 0,''),
    (25, 'username', '用户名', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'KingbaseES8', 0, '2021-03-23 20:35:58', '2021-03-30 16:08:46', 0, 0,''),
    (26, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'KingbaseES8', 0, '2021-03-23 20:35:58', '2021-03-30 16:08:46', 0, 0,''),
    (27, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:pivotal:greenplum://host:port;DatabaseName=database', NULL, '/jdbc:pivotal:greenplum:\\/\\/(.)+/', 'Greenplum', 0, '2021-03-23 20:35:58', '2021-03-30 16:07:17', 0, 0,''),
    (28, 'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'Greenplum', 0, '2021-03-23 20:35:58', '2021-03-30 16:08:46', 0, 0,''),
    (29, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Greenplum', 0, '2021-03-23 20:35:58', '2021-03-30 16:08:46', 0, 0,''),
    (30, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:postgresql://host:port/database', NULL, '/jdbc:postgresql:\\/\\/(.)+/', 'GaussDB', 0, '2021-03-23 20:35:58', '2021-03-30 16:07:17', 0, 0,''),
    (31, 'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'GaussDB', 0, '2021-03-23 20:35:58', '2021-03-30 16:08:46', 0, 0,''),
    (32, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'GaussDB', 0, '2021-03-23 20:35:58', '2021-03-30 16:08:46', 0, 0,''),
    (33, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:gbase://host:port/dbName', NULL, '/jdbc:gbase:\\/\\/(.)+/', 'GBase_8a', 0, '2021-03-23 20:35:58', '2021-03-30 16:07:17', 0, 0,''),
    (34, 'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'GBase_8a', 0, '2021-03-23 20:35:58', '2021-03-30 16:08:46', 0, 0,''),
    (35, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'GBase_8a', 0, '2021-03-23 20:35:58', '2021-03-30 16:08:46', 0, 0,''),
    (36, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:clickhouse://<host>:<port>[/<database>]', NULL, '/jdbc:clickhouse:\\/\\/(.)+/', 'ClickHouse', 0, '2021-03-23 20:35:58', '2021-03-30 16:07:17', 0, 0,''),
    (37, 'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'ClickHouse', 0, '2021-03-23 20:35:58', '2021-03-30 16:08:46', 0, 0,''),
    (38, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'ClickHouse', 0, '2021-03-23 20:35:58', '2021-03-30 16:08:46', 0, 0,''),
    (39, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:mysql://host:port/dbName', NULL, '/jdbc:mysql:\\/\\/(.)+/', 'TiDB', 0, '2021-03-23 20:35:58', '2021-03-30 16:07:17', 0, 0,''),
    (40, 'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'TiDB', 0, '2021-03-23 20:35:58', '2021-03-30 16:08:46', 0, 0,''),
    (41, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'TiDB', 0, '2021-03-23 20:35:58', '2021-03-30 16:08:46', 0, 0,''),
    (42, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:mysql://host:port/dbName', NULL, '/jdbc:mysql:\\/\\/(.)+/', 'AnalyticDB', 0, '2021-03-23 20:35:58', '2021-03-30 16:07:17', 0, 0,''),
    (43, 'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'AnalyticDB', 0, '2021-03-23 20:35:58', '2021-03-30 16:08:46', 0, 0,''),
    (44, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'AnalyticDB', 0, '2021-03-23 20:35:58', '2021-03-30 16:08:46', 0, 0,''),
    (45, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:hive://host:port/dbName', NULL, '/jdbc:(\\w|:)+:\\/\\/(.)+/', 'Hive-1.x', 0, '2021-03-23 20:37:29', '2021-03-30 16:07:17', 0, 0,''),
    (46, 'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Hive-1.x', 0, '2021-03-23 20:37:29', '2021-03-30 16:08:46', 0, 0,''),
    (47, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Hive-1.x', 0, '2021-03-23 20:37:29', '2021-03-30 16:08:46', 0, 0,''),
    (48, 'defaultFS', 'defaultFS', 'Input', 1, 0, NULL, 'hdfs://host:port', NULL, 1, '', NULL, NULL, NULL, 'Hive-1.x', 0, '2021-03-23 20:37:29', '2021-03-30 16:08:46', 0, 0,''),
    (49, 'hadoopConfig', '高可用配置', 'TextAreaWithCopy', 0, 0, NULL, '{\n\"dfs.nameservices\": \"defaultDfs\", \n\"dfs.ha.namenodes.defaultDfs\": \"namenode1\", \n\"dfs.namenode.rpc-address.defaultDfs.namenode1\": \"\", \n\"dfs.client.failover.proxy.provider.defaultDfs\": \"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\" \n}', NULL, 0, '', '高可用模式下的填写规则：\n1、分别要填写：nameservice名称、 namenode名称（多个以逗号分隔）、proxy.provider参数；\n2、所有参数以JSON格式填写；\n3、格式为：\n\"dfs.nameservices\": \"nameservice名称\", \"dfs.ha.namenodes.nameservice名称\": \"namenode名称，以逗号分隔\", \"dfs.namenode.rpc-address.nameservice名称.namenode名称\": \"\", \"dfs.namenode.rpc-address.nameservice名称.namenode名称\": \"\", \"dfs.client.failover.proxy.provider.\nnameservice名称\": \"org.apache.hadoop.\nhdfs.server.namenode.ha.\nConfiguredFailoverProxyProvider\"\n4、详细参数含义请参考《帮助文档》或<a href=\'http://hadoop.apache.org/docs/r2.7.4/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html\'>Hadoop官方文档</a>', NULL, NULL, 'Hive-1.x', 0, '2021-03-23 20:37:29', '2021-03-30 16:08:46', 0, 0,''),
    (50, 'openKerberos', '开启Kerberos认证', 'Kerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Hive-1.x', 0, '2021-03-23 20:37:29', '2021-03-30 16:08:46', 0, 0,''),
    (51, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:hive2://host:port/dbName', NULL, '/jdbc:(\\w|:)+:\\/\\/(.)+/', 'Hive-2.x', 0, '2021-03-23 20:37:30', '2021-03-30 16:07:17', 0, 0,''),
    (52, 'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Hive-2.x', 0, '2021-03-23 20:37:30', '2021-03-30 16:08:46', 0, 0,''),
    (53, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Hive-2.x', 0, '2021-03-23 20:37:30', '2021-03-30 16:08:46', 0, 0,''),
    (54, 'defaultFS', 'defaultFS', 'Input', 1, 0, NULL, 'hdfs://host:port', NULL, 1, '', NULL, NULL, NULL, 'Hive-2.x', 0, '2021-03-23 20:37:30', '2021-03-30 16:08:46', 0, 0,''),
    (55, 'hadoopConfig', '高可用配置', 'TextAreaWithCopy', 0, 0, NULL, '{\n\"dfs.nameservices\": \"defaultDfs\", \n\"dfs.ha.namenodes.defaultDfs\": \"namenode1\", \n\"dfs.namenode.rpc-address.defaultDfs.namenode1\": \"\", \n\"dfs.client.failover.proxy.provider.defaultDfs\": \"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\" \n}', NULL, 0, '', '高可用模式下的填写规则：\n1、分别要填写：nameservice名称、 namenode名称（多个以逗号分隔）、proxy.provider参数；\n2、所有参数以JSON格式填写；\n3、格式为：\n\"dfs.nameservices\": \"nameservice名称\", \"dfs.ha.namenodes.nameservice名称\": \"namenode名称，以逗号分隔\", \"dfs.namenode.rpc-address.nameservice名称.namenode名称\": \"\", \"dfs.namenode.rpc-address.nameservice名称.namenode名称\": \"\", \"dfs.client.failover.proxy.provider.\nnameservice名称\": \"org.apache.hadoop.\nhdfs.server.namenode.ha.\nConfiguredFailoverProxyProvider\"\n4、详细参数含义请参考《帮助文档》或<a href=\'http://hadoop.apache.org/docs/r2.7.4/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html\'>Hadoop官方文档</a>', NULL, NULL, 'Hive-2.x', 0, '2021-03-23 20:37:30', '2021-03-30 16:08:46', 0, 0,''),
    (56, 'openKerberos', '开启Kerberos认证', 'Kerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Hive-2.x', 0, '2021-03-23 20:37:30', '2021-03-30 16:08:46', 0, 0,''),
    (57, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:hive2://host:port/dbName', NULL, '/jdbc:hive2:\\/\\/(.)+/', 'SparkThrift', 0, '2021-03-23 20:37:30', '2021-03-30 16:07:17', 0, 0,''),
    (58, 'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'SparkThrift', 0, '2021-03-23 20:37:30', '2021-03-30 16:08:46', 0, 0,''),
    (59, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'SparkThrift', 0, '2021-03-23 20:37:30', '2021-03-30 16:08:46', 0, 0,''),
    (60, 'defaultFS', 'defaultFS', 'Input', 1, 0, NULL, 'hdfs://host:port', NULL, 1, '', NULL, NULL, NULL, 'SparkThrift', 0, '2021-03-23 20:37:30', '2021-03-30 16:08:46', 0, 0,''),
    (61, 'hadoopConfig', '高可用配置', 'TextAreaWithCopy', 0, 0, NULL, '{\n\"dfs.nameservices\": \"defaultDfs\", \n\"dfs.ha.namenodes.defaultDfs\": \"namenode1\", \n\"dfs.namenode.rpc-address.defaultDfs.namenode1\": \"\", \n\"dfs.client.failover.proxy.provider.defaultDfs\": \"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\" \n}', NULL, 0, '', '高可用模式下的填写规则：\n1、分别要填写：nameservice名称、 namenode名称（多个以逗号分隔）、proxy.provider参数；\n2、所有参数以JSON格式填写；\n3、格式为：\n\"dfs.nameservices\": \"nameservice名称\", \"dfs.ha.namenodes.nameservice名称\": \"namenode名称，以逗号分隔\", \"dfs.namenode.rpc-address.nameservice名称.namenode名称\": \"\", \"dfs.namenode.rpc-address.nameservice名称.namenode名称\": \"\", \"dfs.client.failover.proxy.provider.\nnameservice名称\": \"org.apache.hadoop.\nhdfs.server.namenode.ha.\nConfiguredFailoverProxyProvider\"\n4、详细参数含义请参考《帮助文档》或<a href=\'http://hadoop.apache.org/docs/r2.7.4/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html\'>Hadoop官方文档</a>', NULL, NULL, 'SparkThrift', 0, '2021-03-23 20:37:30', '2021-03-30 16:08:46', 0, 0,''),
    (62, 'openKerberos', '开启Kerberos认证', 'Kerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'SparkThrift', 0, '2021-03-23 20:37:30', '2021-03-30 16:08:46', 0, 0,''),
    (63, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:impala://host:port/dbName', NULL, '/jdbc:impala:\\/\\/(.)+/', 'Impala', 0, '2021-03-23 20:37:30', '2021-03-30 16:07:17', 0, 0,''),
    (64, 'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Impala', 0, '2021-03-23 20:37:30', '2021-03-30 16:08:46', 0, 0,''),
    (65, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Impala', 0, '2021-03-23 20:37:30', '2021-03-30 16:08:46', 0, 0,''),
    (66, 'defaultFS', 'defaultFS', 'Input', 1, 0, NULL, 'hdfs://host:port', NULL, 1, '', NULL, NULL, NULL, 'Impala', 0, '2021-03-23 20:37:30', '2021-03-30 16:08:46', 0, 0,''),
    (67, 'hadoopConfig', '高可用配置', 'TextAreaWithCopy', 0, 0, NULL, '{\n\"dfs.nameservices\": \"defaultDfs\", \n\"dfs.ha.namenodes.defaultDfs\": \"namenode1\", \n\"dfs.namenode.rpc-address.defaultDfs.namenode1\": \"\", \n\"dfs.client.failover.proxy.provider.defaultDfs\": \"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\" \n}', NULL, 0, '', '高可用模式下的填写规则：\n1、分别要填写：nameservice名称、 namenode名称（多个以逗号分隔）、proxy.provider参数；\n2、所有参数以JSON格式填写；\n3、格式为：\n\"dfs.nameservices\": \"nameservice名称\", \"dfs.ha.namenodes.nameservice名称\": \"namenode名称，以逗号分隔\", \"dfs.namenode.rpc-address.nameservice名称.namenode名称\": \"\", \"dfs.namenode.rpc-address.nameservice名称.namenode名称\": \"\", \"dfs.client.failover.proxy.provider.\nnameservice名称\": \"org.apache.hadoop.\nhdfs.server.namenode.ha.\nConfiguredFailoverProxyProvider\"\n4、详细参数含义请参考《帮助文档》或<a href=\'http://hadoop.apache.org/docs/r2.7.4/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html\'>Hadoop官方文档</a>', NULL, NULL, 'Impala', 0, '2021-03-23 20:37:30', '2021-03-30 16:08:46', 0, 0,''),
    (68, 'openKerberos', '开启Kerberos认证', 'Kerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Impala', 0, '2021-03-23 20:37:30', '2021-03-30 16:08:46', 0, 0,''),
    (69, 'accessId', 'AccessId', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'Maxcompute', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (70, 'accessKey', 'AccessKey', 'Input', 1, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Maxcompute', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (71, 'project', 'Project Name', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'Maxcompute', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (72, 'endPoint', 'End Point', 'Input', 0, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'Maxcompute', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (73, 'defaultFS', 'defaultFS', 'Input', 1, 0, NULL, 'hdfs://host:port', NULL, 1, '', NULL, NULL, NULL, 'HDFS', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (74, 'hadoopConfig', '高可用配置', 'TextAreaWithCopy', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'HDFS', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (75, 'openKerberos', '开启Kerberos认证', 'Kerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'HDFS', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (76, 'host', '主机名/IP', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'FTP', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (77, 'port', '端口', 'Integer', 1, 0, NULL, 'FTP默认21, SFTP默认22', NULL, 1, '', NULL, NULL, NULL, 'FTP', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (78, 'username', '用户名', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'FTP', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (79, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'FTP', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (80, 'ftpReact', 'ftpReact', 'FtpReact', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'FTP', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (81, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:hive2://host:port/dbName', NULL, '/jdbc:(\\w|:)+:\\/\\/(.)+/\n', 'CarbonData', 0, '2021-03-23 20:38:06', '2021-03-30 16:07:17', 0, 0,''),
    (82, 'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'CarbonData', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (83, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'CarbonData', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (84, 'carbonReact', 'carbonReact', 'CarbonReact', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'CarbonData', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (85, 'hostPorts', '集群地址', 'TextArea', 1, 0, NULL, '集群地址，例如：IP1:Port,IP2:Port,IP3:Port3，多个IP地址用英文逗号隔开', NULL, 1, '', NULL, NULL, NULL, 'Kudu', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (86, 'others', '其他参数', 'TextAreaWithCopy', 0, 0, NULL, '输入JSON格式的参数，示例及默认参数如下：\n{\n    \"openKerberos\":false,\n    \"user\":\"\",\n    \"keytabPath\":\"\",\n    \"workerCount\":4,\n    \"bossCount\":1,\n    \"operationTimeout\":30000,\n    \"adminOperationTimeout\":30000\n}', NULL, 0, '', NULL, NULL, NULL, 'Kudu', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (87, 'openKerberos', '开启Kerberos认证', 'Kerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Kudu', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (88, 'authURL', 'RESTful URL', 'Input', 1, 0, NULL, 'http://ip:port', NULL, 1, '', '访问Kylin的认证地址，格式为：http://ip:port', NULL, '/http:\\/\\/([\\w, .])+:(.)+/', 'Kylin', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (89, 'username', '用户名', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'Kylin', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (90, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Kylin', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (91, 'project', 'Project', 'Input', 1, 0, NULL, 'DEFAULT', NULL, 0, '', NULL, NULL, NULL, 'Kylin', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (92, 'config', '高可用配置', 'TextAreaWithCopy', 0, 0, NULL, '{\n    \"socketTimeout\":10000,\n    \"connectTimeout\":10000\n}', NULL, 0, '', NULL, NULL, NULL, 'Kylin', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (93, 'hbase_quorum', '集群地址', 'TextArea', 1, 0, NULL, '集群地址，例如：IP1:Port,IP2:Port,IP3:Port/子目录', NULL, 1, '', NULL, NULL, NULL, 'HBase-1.x', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (94, 'hbase_parent', '根目录', 'Input', 0, 0, NULL, 'ZooKeeper中hbase创建的根目录，例如：/hbase', NULL, 0, '', NULL, NULL, NULL, 'HBase-1.x', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (95, 'hbase_other', '其他参数', 'TextArea', 0, 0, NULL, 'hbase.rootdir\": \"hdfs: //ip:9000/hbase', NULL, 0, '', NULL, NULL, NULL, 'HBase-1.x', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (96, 'openKerberos', '开启Kerberos认证', 'HbaseKerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'HBase-1.x', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (97, 'hbase_quorum', '集群地址', 'TextArea', 1, 0, NULL, '集群地址，例如：IP1:Port,IP2:Port,IP3:Port/子目录', NULL, 1, '', NULL, NULL, NULL, 'HBase-2.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (98, 'hbase_parent', '根目录', 'Input', 0, 0, NULL, 'ZooKeeper中hbase创建的根目录，例如：/hbase', NULL, 0, '', NULL, NULL, NULL, 'HBase-2.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (99, 'hbase_other', '其他参数', 'TextArea', 0, 0, NULL, 'hbase.rootdir\": \"hdfs: //ip:9000/hbase', NULL, 0, '', NULL, NULL, NULL, 'HBase-2.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (100, 'openKerberos', '开启Kerberos认证', 'HbaseKerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'HBase-2.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (101, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:phoenix:zk1,zk2,zk3:port/hbase2', NULL, '/jdbc:phoenix:(.)+/', 'Phoenix-4.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:07:17', 0, 0,''),
    (102, 'openKerberos', '开启Kerberos认证', 'Kerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Phoenix-4.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (103, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:phoenix:zk1,zk2,zk3:port/hbase2', NULL, '/jdbc:phoenix:(.)+/', 'Phoenix-5.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:07:17', 0, 0,''),
    (104, 'openKerberos', '开启Kerberos认证', 'Kerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Phoenix-5.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (105, 'address', '集群地址', 'TextArea', 1, 0, NULL, '集群地址，单个节点地址采用host:port形式，多个节点的地址用逗号连接', NULL, 1, '', NULL, NULL, NULL, 'Elasticsearch-5.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (106, 'clusterName', '集群名称', 'Input', 1, 0, NULL, '请输入集群名称', NULL, 0, '{\"length\":{\"max\":128, \"message\":\"不得超过128个字符\"}}', NULL, NULL, NULL, 'Elasticsearch-5.x', 0, '2021-03-23 20:38:07', '2021-04-12 19:31:12', 0, 0,''),
    (107, 'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Elasticsearch-5.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (108, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Elasticsearch-5.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (109, 'address', '集群地址', 'TextArea', 1, 0, NULL, '集群地址，单个节点地址采用host:port形式，多个节点的地址用逗号连接', NULL, 1, '', NULL, NULL, NULL, 'Elasticsearch-6.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (110, 'clusterName', '集群名称', 'Input', 1, 0, NULL, '请输入集群名称', NULL, 0, '{\"length\":{\"max\":128, \"message\":\"不得超过128个字符\"}}', NULL, NULL, NULL, 'Elasticsearch-6.x', 0, '2021-03-23 20:38:07', '2021-04-12 19:31:12', 0, 0,''),
    (111, 'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Elasticsearch-6.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (112, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Elasticsearch-6.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (113, 'address', '集群地址', 'TextArea', 1, 0, NULL, '集群地址，单个节点地址采用host:port形式，多个节点的地址用逗号连接', NULL, 1, '', NULL, NULL, NULL, 'Elasticsearch-7.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (114, 'clusterName', '集群名称', 'Input', 1, 0, NULL, '请输入集群名称', NULL, 0, '{\"length\":{\"max\":128, \"message\":\"不得超过128个字符\"}}', NULL, NULL, NULL, 'Elasticsearch-7.x', 0, '2021-03-23 20:38:07', '2021-04-12 19:31:12', 0, 0,''),
    (115, 'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Elasticsearch-7.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (116, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Elasticsearch-7.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (117, 'hostPorts', '集群地址', 'TextArea', 1, 0, NULL, 'MongoDB集群地址，例如：IP1:Port,IP2:Port,IP3:Port', NULL, 1, '', NULL, NULL, NULL, 'MongoDB', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (118, 'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'MongoDB', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (119, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'MongoDB', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (120, 'database', '数据库', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'MongoDB', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (121, 'redisReact', 'redisReact', 'RedisReact', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Redis', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (122, 'hostname', 'hostname', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'S3', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (123, 'accessKey', 'AccessKey', 'Input', 1, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'S3', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (124, 'secretKey', 'SecretKey', 'Input', 1, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'S3', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (125, 'address', '集群地址', 'TextArea', 0, 1, NULL, '请填写Kafka对应的ZooKeeper集群地址，例如：IP1:Port,IP2：Port,IP3：Port/子目录', NULL, 1, '', NULL, NULL, NULL, 'Kafka-1.x', 0, '2021-03-23 20:38:07', '2021-04-13 17:37:38', 0, 0,''),
    (126, 'brokerList', 'broker地址', 'TextArea', 1, 1, NULL, 'Broker地址，例如IP1:Port,IP2:Port,IP3:Port/子目录', NULL, 1, '', NULL, NULL, NULL, 'Kafka-1.x', 0, '2021-03-23 20:38:07', '2021-04-13 17:37:39', 0, 0,''),
    (128, 'address', '集群地址', 'TextArea', 0, 1, NULL, '请填写Kafka对应的ZooKeeper集群地址，例如：IP1:Port,IP2：Port,IP3：Port/子目录', NULL, 1, '', NULL, NULL, NULL, 'Kafka-2.x', 0, '2021-03-23 20:38:07', '2021-04-13 17:37:40', 0, 0,''),
    (129, 'brokerList', 'broker地址', 'TextArea', 1, 1, NULL, 'Broker地址，例如IP1:Port,IP2:Port,IP3:Port/子目录', NULL, 1, '', NULL, NULL, NULL, 'Kafka-2.x', 0, '2021-03-23 20:38:07', '2021-04-13 17:37:41', 0, 0,''),
    (131, 'address', '集群地址', 'TextArea', 0, 1, NULL, '请填写Kafka对应的ZooKeeper集群地址，例如：IP1:Port,IP2：Port,IP3：Port/子目录', NULL, 1, '', NULL, NULL, NULL, 'Kafka-0.9', 0, '2021-03-23 20:38:07', '2021-04-13 17:37:41', 0, 0,''),
    (132, 'brokerList', 'broker地址', 'TextArea', 1, 1, NULL, 'Broker地址，例如IP1:Port,IP2:Port,IP3:Port/子目录', NULL, 1, '', NULL, NULL, NULL, 'Kafka-0.9', 0, '2021-03-23 20:38:07', '2021-04-13 17:37:43', 0, 0,''),
    (134, 'address', '集群地址', 'TextArea', 0, 1, NULL, '请填写Kafka对应的ZooKeeper集群地址，例如：IP1:Port,IP2：Port,IP3：Port/子目录', NULL, 1, '', NULL, NULL, NULL, 'Kafka-0.10', 0, '2021-03-23 20:38:07', '2021-04-13 17:37:43', 0, 0,''),
    (135, 'brokerList', 'broker地址', 'TextArea', 1, 1, NULL, 'Broker地址，例如IP1:Port,IP2:Port,IP3:Port/子目录', NULL, 1, '', NULL, NULL, NULL, 'Kafka-0.10', 0, '2021-03-23 20:38:07', '2021-04-13 17:37:45', 0, 0,''),
    (137, 'address', '集群地址', 'TextArea', 0, 1, NULL, '请填写Kafka对应的ZooKeeper集群地址，例如：IP1:Port,IP2：Port,IP3：Port/子目录', NULL, 1, '', NULL, NULL, NULL, 'Kafka-0.11', 0, '2021-03-23 20:38:07', '2021-04-13 17:37:45', 0, 0,''),
    (138, 'brokerList', 'broker地址', 'TextArea', 1, 1, NULL, 'Broker地址，例如IP1:Port,IP2:Port,IP3:Port/子目录', NULL, 1, '', NULL, NULL, NULL, 'Kafka-0.11', 0, '2021-03-23 20:38:07', '2021-04-13 17:37:46', 0, 0,''),
    (140, 'address', 'Broker URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'EMQ', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (141, 'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'EMQ', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (142, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'EMQ', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (143, 'url', 'URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '', '多个鉴权参数将以”&“连接拼接在URL后，例如：ws://host:port/test?Username=sanshui&password=xx', NULL, NULL, 'WebSocket', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (144, 'webSocketParams', '鉴权参数', 'WebSocketSub', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'WebSocket', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (145, 'url', 'URL', 'Input', 1, 0, NULL, 'host:port', NULL, 1, '', NULL, NULL, NULL, 'Socket', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (146, 'protocol', 'Protocol', 'Input', 1, 1, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'FTP', 0, '2021-03-23 20:38:06', '2021-03-30 16:08:46', 0, 0,''),
    (147, 'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:presto://host:port/dbName', NULL, '/jdbc:presto:\\/\\/(.)+/', 'Presto', 0, '2021-04-07 14:47:08', '2021-04-07 14:47:14', 0, 0,''),
    (148, 'username', '用户名', 'Input', 1, 0, NULL, NULL, NULL, 1, NULL, NULL, NULL, NULL, 'Presto', 0, '2021-04-07 14:47:08', '2021-04-07 14:47:14', 0, 0,''),
    (149, 'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, NULL, NULL, NULL, NULL, 'Presto', 0, '2021-04-07 14:47:08', '2021-04-07 14:47:14', 0, 0,''),
    (150, 'hostPort', '地址', 'TextArea', 1, 1, NULL, NULL, NULL, 1, NULL, NULL, NULL, NULL, 'Redis', 0, '2021-04-15 19:48:41', '2021-04-15 19:48:48', 0, 0,''),
    (151, 'database', '数据库', 'Input', 1, 1, NULL, NULL, NULL, 1, NULL, NULL, NULL, NULL, 'Redis', 0, '2021-04-15 19:48:41', '2021-04-15 19:48:48', 0, 0,''),
    (152, 'zkHost', '集群地址', 'TextArea', 1, 0, NULL, '集群地址，例如:ip1:port,ip2:port,ip3:port', NULL, 1, NULL, NULL, NULL, NULL, 'Solr-7.x', 0, '2021-05-28 14:07:00', '2021-05-28 14:07:00', 0, 0,''),
    (153, 'chroot', 'chroot', 'Input', 1, 0, NULL, '请输入Zookeeper chroot路径,例如/Solr', NULL, 1, NULL, NULL, NULL, NULL, 'Solr-7.x', 0, '2021-05-28 14:07:00', '2021-05-28 14:07:00', 0, 0,''),
    (154, 'openKerberos', '开启Kerberos认证', 'Kerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Solr-7.x', 0, '2021-03-23 20:37:29', '2021-03-30 16:08:46', 0, 0,''),
    (155, 'kafkaReact', 'kafkaReact', 'KafkaReact', 0, 0, NULL, '', NULL, 0, '', NULL, NULL, NULL, 'Kafka-0.9', 0, '2021-06-01 11:50:07', '2021-06-01 11:50:07', 0, 0,''),
    (156, 'kafkaReact', 'kafkaReact', 'KafkaReact', 0, 0, NULL, '', NULL, 0, '', NULL, NULL, NULL, 'Kafka-0.10', 0, '2021-06-01 11:50:07', '2021-06-01 11:50:07', 0, 0,''),
    (157, 'kafkaReact', 'kafkaReact', 'KafkaReact', 0, 0, NULL, '', NULL, 0, '', NULL, NULL, NULL, 'Kafka-0.11', 0, '2021-06-01 11:50:07', '2021-06-01 11:50:07', 0, 0,''),
    (158, 'kafkaReact', 'kafkaReact', 'KafkaReact', 0, 0, NULL, '', NULL, 0, '', NULL, NULL, NULL, 'Kafka-1.x', 0, '2021-06-01 11:50:07', '2021-06-01 11:50:07', 0, 0,''),
    (159, 'kafkaReact', 'kafkaReact', 'KafkaReact', 0, 0, NULL, '', NULL, 0, '', NULL, NULL, NULL, 'Kafka-2.x', 0, '2021-06-01 11:50:07', '2021-06-01 11:50:07', 0, 0,''),
    (160, 'openKerberos', '开启Kerberos认证', 'Kerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Kafka-1.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (161, 'openKerberos', '开启Kerberos认证', 'Kerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Kafka-2.x', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (162, 'openKerberos', '开启Kerberos认证', 'Kerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Kafka-0.9', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (163, 'openKerberos', '开启Kerberos认证', 'Kerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Kafka-0.10', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (164, 'openKerberos', '开启Kerberos认证', 'Kerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Kafka-0.11', 0, '2021-03-23 20:38:07', '2021-03-30 16:08:46', 0, 0,''),
    (165,'url', 'URL', 'Input', 1, 0, NULL, 'http://localhost:8086', NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', NULL, NULL, '/http:\\/\\/([\\w, .])+:(.)+/', 'InfluxDB-1.x', 0, '2021-06-09 14:49:27', '2021-06-09 14:49:42', 0, 0,''),
    (166,'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'InfluxDB-1.x', 0, '2021-06-09 14:49:27', '2021-06-09 14:49:42', 0, 0,''),
    (167,'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'InfluxDB-1.x', 0, '2021-06-09 14:49:27', '2021-06-09 14:49:42', 0, 0,''),
     (168,'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:hive://host:port/dbName', NULL, '/jdbc:(\\w|:)+:\\/\\/(.)+/', 'Hive-3.x', 0, '2021-06-09 14:49:27', '2021-06-09 14:49:42', 0, 0,''),
    (169,'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Hive-3.x', 0, '2021-06-09 14:49:27', '2021-06-09 14:49:42', 0, 0,''),
    (170,'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Hive-3.x', 0, '2021-06-09 14:49:27', '2021-06-09 14:49:42', 0, 0,''),
    (171,'defaultFS', 'defaultFS', 'Input', 1, 0, NULL, 'hdfs://host:port', NULL, 1, '', NULL, NULL, NULL, 'Hive-3.x', 0, '2021-06-09 14:49:27', '2021-06-09 14:49:42', 0, 0,''),
    (172,'hadoopConfig', '高可用配置', 'TextAreaWithCopy', 0, 0, NULL, '{\n\"dfs.nameservices\": \"defaultDfs\", \n\"dfs.ha.namenodes.defaultDfs\": \"namenode1\", \n\"dfs.namenode.rpc-address.defaultDfs.namenode1\": \"\", \n\"dfs.client.failover.proxy.provider.defaultDfs\": \"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\" \n}', NULL, 0, '', '高可用模式下的填写规则：\n1、分别要填写：nameservice名称、 namenode名称（多个以逗号分隔）、proxy.provider参数；\n2、所有参数以JSON格式填写；\n3、格式为：\n\"dfs.nameservices\": \"nameservice名称\", \"dfs.ha.namenodes.nameservice名称\": \"namenode名称，以逗号分隔\", \"dfs.namenode.rpc-address.nameservice名称.namenode名称\": \"\", \"dfs.namenode.rpc-address.nameservice名称.namenode名称\": \"\", \"dfs.client.failover.proxy.provider.\nnameservice名称\": \"org.apache.hadoop.\nhdfs.server.namenode.ha.\nConfiguredFailoverProxyProvider\"\n4、详细参数含义请参考《帮助文档》或<a href=\'http://hadoop.apache.org/docs/r2.7.4/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html\'>Hadoop官方文档</a>', NULL, NULL, 'Hive-3.x', 0, '2021-06-09 14:49:27', '2021-06-09 14:49:42', 0, 0,''),
    (173,'openKerberos', '开启Kerberos认证', 'Kerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Hive-3.x', 0, '2021-06-09 14:49:27', '2021-06-09 14:49:42', 0, 0,''),
    (174,'region', 'Region', 'Select', 1, 0, NULL, '', NULL, 0, '', NULL, NULL, NULL, 'AWS S3', 0, '2021-06-21 22:07:27', '2021-06-21 22:07:27', 0, 0,"[{key:'1',value:'cn-north-1',label:'cn-north-1 (北京)'},{key:'2',value:'cn-northwest-1',label:'cnnorthwest-1 (宁夏)'}]"),
    (175,'accessKey', 'ACCESS KEY', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL, 'AWS S3', 0, '2021-06-21 22:07:27', '2021-06-21 22:07:27', 0, 0,''),
    (176,'secretKey', 'SECRET KEY', 'Password', 1, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'AWS S3', 0, '2021-06-21 22:07:27', '2021-06-21 22:07:27', 0, 0,''),
    (177,'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1,  '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:hive2://host:port/dbName', NULL, '/jdbc:(\\w|:)+:\\/\\/(.)+/', 'Inceptor', 0, '2021-06-21 22:07:27', '2021-06-21 22:07:27', 0, 0,''),
    (178,'username', '用户名', 'Input', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Inceptor', 0, '2021-06-21 22:07:27', '2021-06-21 22:07:27', 0, 0,''),
    (179,'password', '密码', 'Password', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Inceptor', 0, '2021-06-21 22:07:27', '2021-06-21 22:07:27', 0, 0,''),
    (180,'defaultFS', 'defaultFS', 'Input', 1, 0, NULL, 'hdfs://host:port', NULL, 1, '', NULL, NULL, NULL, 'Inceptor', 0, '2021-06-21 22:07:27', '2021-06-21 22:07:27', 0, 0,''),
    (181,'metaStoreUris', 'hive.metastore.uris', 'Input', 0, 0, NULL, '', NULL, 0, '', 'hive.metastore.uris仅在做事务表的写同步时必填', NULL, NULL, 'Inceptor', 0, '2021-06-21 22:07:27', '2021-06-21 22:07:27', 0, 0,''),
    (182,'hadoopConfig', '高可用配置', 'TextAreaWithCopy', 0, 0, NULL, '{\n\"dfs.nameservices\": \"defaultDfs\", \n\"dfs.ha.namenodes.defaultDfs\": \"namenode1\", \n\"dfs.namenode.rpc-address.defaultDfs.namenode1\": \"\", \n\"dfs.client.failover.proxy.provider.defaultDfs\": \"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\" \n}', NULL, 0, '', '高可用模式下的填写规则：\n1、分别要填写：nameservice名称、 namenode名称（多个以逗号分隔）、proxy.provider参数；\n2、所有参数以JSON格式填写；\n3、格式为：\n\"dfs.nameservices\": \"nameservice名称\", \"dfs.ha.namenodes.nameservice名称\": \"namenode名称，以逗号分隔\", \"dfs.namenode.rpc-address.nameservice名称.namenode名称\": \"\", \"dfs.namenode.rpc-address.nameservice名称.namenode名称\": \"\", \"dfs.client.failover.proxy.provider.\nnameservice名称\": \"org.apache.hadoop.\nhdfs.server.namenode.ha.\nConfiguredFailoverProxyProvider\"\n4、详细参数含义请参考《帮助文档》或<a href=\'http://hadoop.apache.org/docs/r2.7.4/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html\'>Hadoop官方文档</a>', NULL, NULL, 'Inceptor', 0, '2021-06-21 22:07:27', '2021-06-21 22:07:27', 0, 0,''),
    (183,'openKerberos', '开启Kerberos认证', 'Kerberos', 0, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL, 'Inceptor', 0, '2021-06-21 22:07:27', '2021-06-21 22:07:27', 0, 0,''),
    (184,'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:postgresql://host:port/database', NULL, '/jdbc:postgresql:\\/\\/(.)+/','ADB_PostgreSQL',0, '2021-06-01 12:22:10', '2021-06-01 12:22:10', 0, 0,''),
    (185,'username', '用户名', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL,'ADB_PostgreSQL', 0, '2021-06-01 12:22:10', '2021-06-01 12:22:10', 0, 0,''),
    (186,'password', '密码', 'Password', 1, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL,'ADB_PostgreSQL', 0, '2021-06-01 12:22:10', '2021-06-01 12:22:10', 0, 0,''),
    (187,'jdbcUrl', 'JDBC URL', 'Input', 1, 0, NULL, NULL, NULL, 1, '{\"regex\":{\"message\":\"JDBC URL格式不符合规则!\"}}', '示例：jdbc:vertica://host:port/dbName', NULL, '/jdbc:vertica:\\/\\/(.)+/','Vertica', 0, '2021-06-01 12:22:10', '2021-06-01 12:22:10', 0, 0,''),
    (188,'username', '用户名', 'Input', 1, 0, NULL, NULL, NULL, 1, '', NULL, NULL, NULL,'Vertica', 0, '2021-06-01 12:22:10', '2021-06-01 12:22:10', 0, 0,''),
    (189,'password', '密码', 'Password', 1, 0, NULL, NULL, NULL, 0, '', NULL, NULL, NULL,'Vertica', 0, '2021-06-01 12:22:10', '2021-06-01 12:22:10', 0, 0,'')
    ;

-- 在数据源版本表dsc_version中新增一条数据
INSERT INTO `dsc_version` (`data_type`, `data_version`, `sorted`, `is_deleted`, `gmt_create`, `gmt_modified`, `create_user_id`, `modify_user_id`)VALUES
	( 'Hive', '3.x', 2, 0, '2021-06-09 14:49:27', '2021-06-09 14:49:42', 0, 0);


-- 在数据源和产品映射表dsc_app_mapping表中新增一条数据
INSERT INTO `dsc_app_mapping` (`app_type`, `data_type`, `data_version`, `is_deleted`, `gmt_create`, `gmt_modified`, `create_user_id`, `modify_user_id`)
VALUES
	(1, 'Hive', '3.x', 0, '2021-06-09 14:49:27', '2021-06-09 14:49:42', 0, 0),
	(7, 'Hive', '3.x', 0, '2021-06-09 14:49:27', '2021-06-09 14:49:42', 0, 0);

